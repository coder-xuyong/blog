import{_ as e,c as t,b as a,o as i}from"./app-Bv24STir.js";const p={};function n(s,o){return i(),t("div",null,o[0]||(o[0]=[a('<h1 id="sqoop" tabindex="-1"><a class="header-anchor" href="#sqoop"><span>Sqoop</span></a></h1><blockquote><p><strong>Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。</strong></p></blockquote><h2 id="sqoop-简介" tabindex="-1"><a class="header-anchor" href="#sqoop-简介"><span>Sqoop 简介</span></a></h2><p><strong>Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。</strong></p><ul><li>Hadoop：HDFS、Hive、HBase、Inceptor、Hyperbase</li><li>面向大数据集的批量导入导出</li><li>将输入数据集分为 N 个切片，然后启动 N 个 Map 任务并行传输</li><li>支持全量、增量两种传输方式</li></ul><h3 id="提供多种-sqoop-连接器" tabindex="-1"><a class="header-anchor" href="#提供多种-sqoop-连接器"><span>提供多种 Sqoop 连接器</span></a></h3><h4 id="内置连接器" tabindex="-1"><a class="header-anchor" href="#内置连接器"><span>内置连接器</span></a></h4><ul><li>经过优化的专用 RDBMS 连接器：MySQL、PostgreSQL、Oracle、DB2、SQL Server、Netzza 等</li><li>通用的 JDBC 连接器：支持 JDBC 协议的数据库</li></ul><h4 id="第三方连接器" tabindex="-1"><a class="header-anchor" href="#第三方连接器"><span>第三方连接器</span></a></h4><ul><li>数据仓库：Teradata</li><li>NoSQL 数据库：Couchbase</li></ul><h3 id="sqoop-版本" tabindex="-1"><a class="header-anchor" href="#sqoop-版本"><span>Sqoop 版本</span></a></h3><h4 id="sqoop-1-优缺点" tabindex="-1"><a class="header-anchor" href="#sqoop-1-优缺点"><span>Sqoop 1 优缺点</span></a></h4><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-architecture.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>优点</p><ul><li>架构简单</li><li>部署简单</li><li>功能全面</li><li>稳定性较高</li><li>速度较快</li></ul><p>缺点</p><ul><li>访问方式单一</li><li>命令行方式容易出错，格式紧耦合</li><li>安全机制不够完善，存在密码泄露风险</li></ul><h4 id="sqoop-2-优缺点" tabindex="-1"><a class="header-anchor" href="#sqoop-2-优缺点"><span>Sqoop 2 优缺点</span></a></h4><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-v2-architecture.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>优点</p><ul><li>访问方式多样</li><li>集中管理连接器</li><li>安全机制较完善</li><li>支持多用户</li></ul><p>缺点</p><ul><li>架构较复杂</li><li>部署较繁琐</li><li>稳定性一般</li><li>速度一般</li></ul><h2 id="sqoop-原理" tabindex="-1"><a class="header-anchor" href="#sqoop-原理"><span>Sqoop 原理</span></a></h2><h3 id="导入" tabindex="-1"><a class="header-anchor" href="#导入"><span>导入</span></a></h3><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-import.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="导出" tabindex="-1"><a class="header-anchor" href="#导出"><span>导出</span></a></h3><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-export.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure>',28)]))}const l=e(p,[["render",n],["__file","index.html.vue"]]),c=JSON.parse('{"path":"/pages/773408/","title":"sqoop","lang":"zh-CN","frontmatter":{"title":"sqoop","date":"2020-09-09T17:53:08.000Z","order":2,"categories":["大数据","其他"],"tags":["大数据","Sqoop"],"permalink":"/pages/773408/","description":"Sqoop Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Sqoop 简介 Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Hadoop：HDFS、Hive、HBase、Inceptor、Hyperbase 面向大数据集的批量导入导出 将输入数据集分为 N 个切片，然后启动 N 个 ...","head":[["meta",{"property":"og:url","content":"https://coder-xuyong.github.io/blog/pages/773408/"}],["meta",{"property":"og:site_name","content":"coder-xuyong"}],["meta",{"property":"og:title","content":"sqoop"}],["meta",{"property":"og:description","content":"Sqoop Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Sqoop 简介 Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。 Hadoop：HDFS、Hive、HBase、Inceptor、Hyperbase 面向大数据集的批量导入导出 将输入数据集分为 N 个切片，然后启动 N 个 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-architecture.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-10T02:14:26.000Z"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:tag","content":"Sqoop"}],["meta",{"property":"article:published_time","content":"2020-09-09T17:53:08.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-10T02:14:26.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"sqoop\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-architecture.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-v2-architecture.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-import.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/bigdata/Sqoop/sqoop-export.png\\"],\\"datePublished\\":\\"2020-09-09T17:53:08.000Z\\",\\"dateModified\\":\\"2025-06-10T02:14:26.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"xuyong\\",\\"url\\":\\"https://github.com/coder-xuyong\\"}]}"]]},"headers":[{"level":2,"title":"Sqoop 简介","slug":"sqoop-简介","link":"#sqoop-简介","children":[{"level":3,"title":"提供多种 Sqoop 连接器","slug":"提供多种-sqoop-连接器","link":"#提供多种-sqoop-连接器","children":[]},{"level":3,"title":"Sqoop 版本","slug":"sqoop-版本","link":"#sqoop-版本","children":[]}]},{"level":2,"title":"Sqoop 原理","slug":"sqoop-原理","link":"#sqoop-原理","children":[{"level":3,"title":"导入","slug":"导入","link":"#导入","children":[]},{"level":3,"title":"导出","slug":"导出","link":"#导出","children":[]}]}],"git":{"createdTime":1749521666000,"updatedTime":1749521666000,"contributors":[{"name":"XuYong","username":"XuYong","email":"1299461580@qq.com","commits":1,"url":"https://github.com/XuYong"}]},"readingTime":{"minutes":1.16,"words":348},"filePathRelative":"posts/16.大数据/99.其他/02.sqoop.md","localizedDate":"2020年9月9日","excerpt":"\\n<blockquote>\\n<p><strong>Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。</strong></p>\\n</blockquote>\\n<h2>Sqoop 简介</h2>\\n<p><strong>Sqoop 是一个主要在 Hadoop 和关系数据库之间进行批量数据迁移的工具。</strong></p>\\n<ul>\\n<li>Hadoop：HDFS、Hive、HBase、Inceptor、Hyperbase</li>\\n<li>面向大数据集的批量导入导出</li>\\n<li>将输入数据集分为 N 个切片，然后启动 N 个 Map 任务并行传输</li>\\n<li>支持全量、增量两种传输方式</li>\\n</ul>","autoDesc":true}');export{l as comp,c as data};
